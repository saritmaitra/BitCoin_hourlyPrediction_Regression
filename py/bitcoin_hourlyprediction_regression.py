# -*- coding: utf-8 -*-
"""BitCoin_hourlyPrediction_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14coI2hnsTWX7N1FT1jyJ_SRgRnwBXI3b
"""

print('Dependencies loading......')

!pip install pyforest
from pyforest import *
import datetime, pickle, copy, warnings
!pip install cryptocompare
import cryptocompare
import requests
!pip install plotly
!pip install cufflinks
import plotly.express as px
import plotly.graph_objects as go
from time import time
from pandas import DataFrame, concat
from sklearn import metrics
from sklearn.linear_model import LinearRegression, ElasticNet
from sklearn import preprocessing
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error, r2_score
from math import sqrt
!pip install tscv

print('Complete....')

start = time()
print('Starting program ( hourly data)....')

apiKey = "xxxxxxxx"
url = "https://min-api.cryptocompare.com/data/histohour"

# BTC data
payload = {
    "api_key": apiKey,
    "fsym": "BTC",
    "tsym": "USD",
    "limit": 2000
}

result = requests.get(url, params=payload).json()

btc1 = DataFrame(result['Data'])
btc1['time'] = pd.to_datetime(btc1['time'],unit='s')
btc1.set_index('time',inplace=True)

# 2nd 2000 data
payload = {
    "api_key": apiKey,
    "fsym": "BTC",
    "tsym": "USD",
    "limit": 2000,
    "toTs": (1601632800)
}

result = requests.get(url, params=payload).json()

btc2 = DataFrame(result['Data'])
btc2['time'] = pd.to_datetime(btc2['time'],unit='s')
btc2.set_index('time',inplace=True)

# 3rd 2000 data
payload = {
    "api_key": apiKey,
    "fsym": "BTC",
    "tsym": "USD",
    "limit": 2000,
    "toTs": (1593572400)
}

result = requests.get(url, params=payload).json()

btc3 = DataFrame(result['Data'])
btc3['time'] = pd.to_datetime(btc3['time'],unit='s')
btc3.set_index('time',inplace=True)

# 4th 2000 data
payload = {
    "api_key": apiKey,
    "fsym": "BTC",
    "tsym": "USD",
    "limit": 2000,
    "toTs": (1596571200)
}

result = requests.get(url, params=payload).json()

btc4 = DataFrame(result['Data'])
btc4['time'] = pd.to_datetime(btc4['time'],unit='s')
btc4.set_index('time',inplace=True)

# combining BTC dataframe
com1 = btc2.append(btc1)
com2 = btc3.append(com1)
btc = btc4.append(com2)
# saving btc data set
#btc.to_csv("bitcoin.csv")


# ETH DATA
payload = {
    "api_key": apiKey,
    "fsym": "ETH",
    "tsym": "USD",
    "limit": 2000
}

result = requests.get(url, params=payload).json()
eth1 = DataFrame(result['Data'])
eth1['time'] = pd.to_datetime(eth1['time'],unit='s')
eth1.set_index('time',inplace=True)

# 2nd 2000 data
payload = {
    "api_key": apiKey,
    "fsym": "ETH",
    "tsym": "USD",
    "limit": 2000,
    "toTs": (1601632800)
}

result = requests.get(url, params=payload).json()
eth2 = DataFrame(result['Data'])
eth2['time'] = pd.to_datetime(eth2['time'],unit='s')
eth2.set_index('time',inplace=True)

# 3rd 2000 data
payload = {
    "api_key": apiKey,
    "fsym": "ETH",
    "tsym": "USD",
    "limit": 2000,
    "toTs": (1593572400)
}

result = requests.get(url, params=payload).json()
eth3 = DataFrame(result['Data'])
eth3['time'] = pd.to_datetime(eth3['time'],unit='s')
eth3.set_index('time',inplace=True)

# 4th ETH 2000 data
payload = {
    "api_key": apiKey,
    "fsym": "ETH",
    "tsym": "USD",
    "limit": 2000,
    "toTs": (1596571200)
}

result = requests.get(url, params=payload).json()

eth4 = DataFrame(result['Data'])
eth4['time'] = pd.to_datetime(eth4['time'],unit='s')
eth4.set_index('time',inplace=True)

# combining BTC dataframe
com1 = eth2.append(eth1)
com2 = eth3.append(com1)
eth = eth4.append(com2)

# saving ETH data set
#eth.to_csv("Ethereum.csv")

# LTC data
payload = {
    "api_key": apiKey,
    "fsym": "LTC",
    "tsym": "USD",
    "limit": 2000
}
result = requests.get(url, params=payload).json()
ltc1 = DataFrame(result['Data'])
ltc1['time'] = pd.to_datetime(ltc1['time'],unit='s')
ltc1.set_index('time',inplace=True)

# 2nd 2000 data
payload = {
    "api_key": apiKey,
    "fsym": "LTC",
    "tsym": "USD",
    "limit": 2000,
    "toTs": (1601632800)
}

result = requests.get(url, params=payload).json()
ltc2 = DataFrame(result['Data'])
ltc2['time'] = pd.to_datetime(ltc2['time'],unit='s')
ltc2.set_index('time',inplace=True)

# 3rd 2000 data
payload = {
    "api_key": apiKey,
    "fsym": "LTC",
    "tsym": "USD",
    "limit": 2000,
    "toTs": (1593572400)
}

result = requests.get(url, params=payload).json()
ltc3 = DataFrame(result['Data'])
ltc3['time'] = pd.to_datetime(ltc3['time'],unit='s')
ltc3.set_index('time',inplace=True)

# 4th ETH 2000 data
payload = {
    "api_key": apiKey,
    "fsym": "ETH",
    "tsym": "USD",
    "limit": 2000,
    "toTs": (1596571200)
}

result = requests.get(url, params=payload).json()

ltc4 = DataFrame(result['Data'])
ltc4['time'] = pd.to_datetime(ltc4['time'],unit='s')
ltc4.set_index('time',inplace=True)

# combining dataframe
com1 = ltc2.append(ltc1)
com2 = ltc3.append(com1)
ltc = ltc4.append(com2)

# saving ltc data set
#ltc.to_csv("litecoin.csv")

# --Data Selection
from pandas import DataFrame, concat

df = DataFrame({'ETH': eth.close})
dataframe = concat([btc, df], axis=1)
dataframe.drop(columns = ['conversionType','conversionSymbol'], axis=1, inplace=True)
print(dataframe)

"""##Feature Engineering:"""

values = DataFrame(btc.close.values)
lags = 8
columns = [values]

for i in range(1,(lags + 1)):
    columns.append(values.shift(i))

dt = concat(columns, axis=1)

columns = ['Lag']

for i in range(1,(lags + 1)):
    columns.append('Lag' + str(i))

dt.columns = columns

dt.index = dataframe.index

dataframe = concat([dataframe, dt], axis=1)

dataframe.dropna(inplace=True)

dataframe['S_10'] = dataframe['close'].rolling(window=10).mean()

dataframe['Corr'] = dataframe['close'].rolling(window=10).corr(dataframe['S_10'])

dataframe['d_20'] = dataframe['close'].shift(480)

dataframe['5EMA'] = (dataframe['close'].ewm(span=5,adjust=True,ignore_na=True).mean())

dataframe['10EMA'] = (dataframe['close'].ewm(span=10,adjust=True,ignore_na=True).mean())

dataframe['20EMA'] = (dataframe['close'].ewm(span=20,adjust=True,ignore_na=True).mean())

dataframe['mean'] = (dataframe['low'] + dataframe['high'])/2

dataframe['returns'] = (dataframe['close'] - dataframe['open']) / dataframe['open'] * 100.0

dataframe['volume'] = dataframe['volumeto'] - dataframe['volumefrom']

dataframe.drop(['volumefrom', 'volumeto'], 1, inplace=True)

dataframe.dropna(inplace=True)

dataframe = dataframe.drop(['Lag'], axis=1)

dataframe = dataframe.astype(float)

dataframe = dataframe.sort_index(ascending=True)
#dataframe.head(2)

fcast_col = 'close' # creating label

fcast_out = int(12) # prediction for next 24 hrs

dataframe['label'] = dataframe[fcast_col].shift(-fcast_out)

# save data
#dataframe.to_csv('btc_hr.csv', header=True)
#dataframe.dropna(inplace=True)

"""## X,y dataset"""

X = np.array(dataframe.drop(['label'], axis=1))

# normalize data
from sklearn import preprocessing

X = preprocessing.scale(X)

X_fcast_out = X[-fcast_out:]

X = X[:-fcast_out]

dataframe.dropna(inplace=True)

y = np.array(dataframe['label'])

"""## Time-series split"""

# time series data split 
from sklearn.model_selection import TimeSeriesSplit

#from tscv import GapKFold
#gkcv = GapKFold(n_splits=5, gap_before=2, gap_after=1);

# Split the data into train and test data set
tscv = TimeSeriesSplit(n_splits=5);
for train_index, test_index in tscv.split(X, y):
    X_train, X_test = X[train_index], X[test_index];
    y_train, y_test = y[train_index], y[test_index];

"""##Regression model:"""

# regression model
lm = ElasticNet(alpha = 0.0001, l1_ratio = 0.5, random_state = 0).fit(X_train, y_train)

# cross validated accucary on train set
from sklearn.model_selection import cross_val_score

scores = cross_val_score(lm, X_train, y_train, cv=tscv)

print("Training Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

import sklearn.externals
import joblib

# Save model to file in the current working directory
joblib_file = "joblib_linmodel.pkl" 
 
joblib.dump(lm, joblib_file)

# Load from file
joblib_linmodel = joblib.load(joblib_file)

"""##Prediction on training-dataset:"""

# prediction on training
tr_pred = joblib_linmodel.predict(X_train)

r_squared = r2_score(y_train, tr_pred)

mae = np.mean(abs(tr_pred - y_train))

rmse = np.sqrt(np.mean((tr_pred - y_train)**2))

rae = np.mean(abs(tr_pred - y_train)) / np.mean(abs(y_train - np.mean(y_train)))

rse = np.mean((tr_pred - y_train)**2) / np.mean((y_train - np.mean(y_train))**2)

sum_df = DataFrame(index = ['R-squared', 'Mean Absolute Error', 'Root Mean Squared Error',
                                'Relative Absolute Error', 'Relative Squared Error'])

sum_df['Training metrics'] = [r_squared, mae, rmse, rae, rse]

"""##Prediction on test dataset:"""

# prediction of test
te_pred = joblib_linmodel.predict(X_test)

r_squared = r2_score(y_test, te_pred)

mae = np.mean(abs(te_pred - y_test))

rmse = np.sqrt(np.mean((te_pred - y_test)**2))

rae = np.mean(abs(te_pred - y_test)) / np.mean(abs(y_test - np.mean(y_test)))

rse = np.mean((te_pred - y_test)**2) / np.mean((y_test - np.mean(y_test))**2)

sum_df['Validation metrics'] = [r_squared, mae, rmse, rae, rse]

sum_df= sum_df.round(decimals=3)

print(sum_df)

"""## Residuals calculations:"""

residuals = [y_test[i]-te_pred[i] for i in range(len(te_pred))]

residuals = DataFrame(residuals)

error = residuals.mean()

"""###Mean absolute error:"""

from sklearn.metrics import mean_absolute_error

tr_mae = mean_absolute_error(y_train, tr_pred)

te_mae = mean_absolute_error(y_test, te_pred)

"""## Actual vs prediction test:"""

y_test = DataFrame(y_test) # actual

y_test.index = btc.index[-len(y_test):]

y_test.rename(columns = {0: 'Actual'}, inplace = True)
#y_test.tail()

"""## Actual vs prediction validation"""

from pandas import DataFrame, concat

predict = DataFrame(te_pred) # prediction

predict.rename(columns = {0: 'Predicted'}, inplace = True)

predict.index = y_test.index

"""##Visualization:"""

fig = go.Figure()

fig.add_trace(go.Scatter(x = btc['close'].index, y = btc['close'],
                         marker = dict(color = "red"), name = "Actual close price"))

fig.add_trace(go.Scatter(x = predict.index, y = predict['Predicted'], marker = dict(
        color = "green"), name = "Prediction"))

fig.update_xaxes(showline = True, linewidth = 2, linecolor = 'black', mirror = True, showspikes = True,)

fig.update_yaxes(showline = True, linewidth = 2, linecolor = 'black', mirror = True, showspikes = True,)

fig.update_layout(
    title= "Actual vs Prediction", 
    yaxis_title = 'BTC (US$)',
    hovermode = "x",
    hoverdistance = 100, # Distance to show hover label of data point
    spikedistance = 1000)

fig.update_layout(autosize = False, width = 1000, height = 400,)

fig.show()

"""# Forecast future values"""

fcast1 = DataFrame(joblib_linmodel.predict(X_fcast_out)); #set that will contain the forecasted data 

#fcast1 = fcast1 + error # adding absolute error
fcast1 = fcast1 + error # adding absolute error

# assigning names to columns
fcast1.rename(columns = {0: 'Forecast'}, inplace = True)

d = btc.tail(fcast_out)

d.reset_index(inplace = True)

d = d.append(DataFrame({'time': pd.date_range(start = d.time.iloc[-1], 
                                             periods = (len(d)+1), freq = 'H', closed = 'right')}))

d.set_index('time', inplace = True)

d = d.tail(fcast_out)

fcast1.index = d.index

print('12 hours forecast (hourly):')
fcast1.reset_index(inplace=True)

print(fcast1)

"""##Visualization"""

fig = go.Figure()

n = fcast1.time[0]

fig.add_trace(go.Scatter(x = btc.index[-200:], y = btc.close[-200:],
                         marker = dict(color = "red"), name = "Actual close price"))

fig.add_trace(go.Scatter(x = fcast1['time'], y = fcast1['Forecast'], marker = dict(
        color = "green"), name = "Future prediction"))

fig.update_xaxes(showline = True, linewidth = 2, linecolor = 'black', mirror = True, showspikes = True,)

fig.update_yaxes(showline = True, linewidth = 2, linecolor = 'black', mirror = True, showspikes = True,)

fig.update_layout(
    title= "12 hrs close Price Forecast", 
    yaxis_title = 'BTC (US$)',
    hovermode = "x",
    hoverdistance = 100, # Distance to show hover label of data point
    spikedistance = 1000,
    shapes = [dict(x0 = n, x1 = n, y0 = 0, y1 = 1, xref = 'x', yref = 'paper', line_width = 2)],
    annotations = [dict(x = n, y = 0.05, xref = 'x', yref = 'paper', showarrow = False, 
                        xanchor = 'left', text = 'Prediction')])

fig.update_layout(autosize = False, width = 1000, height = 400)

fig.show()

elapse = time() - start
print('Time elapsed:, ', elapse)

import threading

def tick():
    threading.Timer(3600.0, tick).start() # called every hour

    print("tick tock tick tock......see you in an hour again !!!")

tick()